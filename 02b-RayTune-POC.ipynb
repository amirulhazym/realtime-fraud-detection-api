{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4727bf-9166-484c-b5aa-7666d8a403ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ray Tune Core API Implementation ---\n",
      "Imports successful.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Imports ---\n",
    "print(\"--- Ray Tune Core API Implementation ---\")\n",
    "\n",
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Scikit-learn for pipeline, splitting, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import recall_score\n",
    "# Optional: If you added StandardScaler or other preprocessing in the pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Imbalanced-learn for SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Ray Tune\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "print(\"Imports successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5071932-97a8-46c6-adae-8ebb28993bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation Complete.\n",
      "X_train_fe shape: (800000, 11)\n",
      "y_train shape: (800000,)\n",
      "X_test_fe shape: (200000, 11)\n",
      "y_test shape: (200000,)\n",
      "Pipeline object created: Pipeline(steps=[('xgboost',\n",
      "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                               colsample_bylevel=None, colsample_bynode=None,\n",
      "                               colsample_bytree=None, device=None,\n",
      "                               early_stopping_rounds=None,\n",
      "                               enable_categorical=False, eval_metric='logloss',\n",
      "                               feature_types=None, feature_weights=None,\n",
      "                               gamma=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=None,\n",
      "                               max_bin=None, max_cat_threshold=None,\n",
      "                               max_cat_to_onehot=None, max_delta_step=None,\n",
      "                               max_depth=None, max_leaves=None,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, multi_strategy=None,\n",
      "                               n_estimators=None, n_jobs=None,\n",
      "                               num_parallel_tree=None, ...))])\n"
     ]
    }
   ],
   "source": [
    "# Combined Data Loading, Preprocessing, Splitting, Feature Engineering, and Pipeline Creation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "import gc # For memory management\n",
    "\n",
    "# --- Load and Sample Data ---\n",
    "hf_csv_url = \"hf://datasets/MatrixIA/FraudData/FraudData.csv\"\n",
    "df_full = pd.read_csv(hf_csv_url) # Requires huggingface_hub\n",
    "sample_size = 1000000\n",
    "df = df_full.head(sample_size).copy()\n",
    "del df_full\n",
    "gc.collect()\n",
    "\n",
    "# --- Preprocessing (Selection, Encoding, Define X/y) ---\n",
    "features_to_keep = ['step', 'type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "target = 'isFraud'\n",
    "df_processed = df[features_to_keep + [target]].copy()\n",
    "df_processed = pd.get_dummies(df_processed, columns=['type'], drop_first=True, dtype=int)\n",
    "X = df_processed.drop(target, axis=1)\n",
    "y = df_processed[target]\n",
    "del df # Clean up intermediate dataframe\n",
    "gc.collect()\n",
    "\n",
    "# --- Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "del X, y # Clean up intermediate variables\n",
    "gc.collect()\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "X_train_fe = X_train.copy()\n",
    "X_test_fe = X_test.copy()\n",
    "epsilon = 1e-6\n",
    "X_train_fe['amt_ratio_orig'] = (X_train_fe['amount'] / (X_train_fe['oldbalanceOrg'] + epsilon)).fillna(0)\n",
    "X_test_fe['amt_ratio_orig'] = (X_test_fe['amount'] / (X_test_fe['oldbalanceOrg'] + epsilon)).fillna(0)\n",
    "del X_train, X_test # Clean up original splits if only feature-engineered ones are needed next\n",
    "gc.collect()\n",
    "\n",
    "# --- Build Pipeline Object ---\n",
    "pipeline_steps = [\n",
    "    # Add scaler here if needed: e.g., ('scaler', StandardScaler()),\n",
    "    ('xgboost', xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "]\n",
    "pipeline_obj = Pipeline(steps=pipeline_steps)\n",
    "\n",
    "# --- Verification (Optional - Can be commented out after confirmation) ---\n",
    "print(f\"Data Preparation Complete.\")\n",
    "print(f\"X_train_fe shape: {X_train_fe.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test_fe shape: {X_test_fe.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"Pipeline object created: {pipeline_obj}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "081059a3-ecd8-4177-aa21-fa170f0fdcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray Tune training function 'train_fraud_model_ray' defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Define Ray Tune Training Function ---\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import recall_score\n",
    "from ray import tune\n",
    "\n",
    "def train_fraud_model_ray(config):\n",
    "    \"\"\"Trains and validates one trial for Ray Tune.\"\"\"\n",
    "    # Assumes X_train_fe and y_train are accessible in the outer scope\n",
    "\n",
    "    # 1. Internal Train/Validation Split\n",
    "    try:\n",
    "        X_tune_train, X_tune_val, y_tune_train, y_tune_val = train_test_split(\n",
    "            X_train_fe, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "        )\n",
    "    except NameError:\n",
    "         print(\"ERROR in train_fraud_model_ray: Could not access X_train_fe or y_train.\")\n",
    "         tune.report(recall=0.0, error=\"Data loading failed\")\n",
    "         return\n",
    "\n",
    "    # 2. Apply SMOTE to Internal Training Split\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_tune_train_res, y_tune_train_res = smote.fit_resample(X_tune_train, y_tune_train)\n",
    "\n",
    "    # 3. Prepare DMatrix\n",
    "    dtrain = xgb.DMatrix(X_tune_train_res, label=y_tune_train_res)\n",
    "    dval = xgb.DMatrix(X_tune_val, label=y_tune_val)\n",
    "\n",
    "    # 4. Train using xgb.train API\n",
    "    evals_result = {}\n",
    "    try:\n",
    "        bst = xgb.train(\n",
    "            params=config,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=config.get(\"n_estimators\", 100), # Use n_estimators from config\n",
    "            evals=[(dval, \"eval\")],\n",
    "            evals_result=evals_result,\n",
    "            verbose_eval=False,\n",
    "            early_stopping_rounds=10\n",
    "        )\n",
    "\n",
    "        # 5. Evaluate on Internal Validation Set\n",
    "        y_pred_val_proba = bst.predict(dval)\n",
    "        y_pred_val_labels = (y_pred_val_proba > 0.5).astype(int) # Threshold probabilities\n",
    "        validation_recall = recall_score(y_tune_val, y_pred_val_labels, pos_label=1, zero_division=0)\n",
    "\n",
    "        # 6. Report Results to Ray Tune\n",
    "        tune.report(recall=validation_recall, done=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during training/evaluation in trial: {e}\")\n",
    "        tune.report(recall=0.0, error=str(e), done=True) # Report failure\n",
    "\n",
    "print(\"Ray Tune training function 'train_fraud_model_ray' defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c79dc190-d800-4234-946f-dd18a8e85a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining Ray Tune search space and tuner...\n",
      "Ray Tune Tuner configured successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Define Ray Tune Search Space and Tuner ---\n",
    "from ray import tune # Ensure tune is imported\n",
    "\n",
    "print(\"\\nDefining Ray Tune search space and tuner...\")\n",
    "\n",
    "# Define parameter search space using tune.* functions\n",
    "# These keys MUST match the parameters expected by xgb.train within your training function\n",
    "param_space = {\n",
    "    # XGBoost Training Parameters (params argument for xgb.train)\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": [\"logloss\", \"recall\"], # Track multiple metrics if desired\n",
    "    \"eta\": tune.loguniform(1e-4, 1e-1),  # Learning rate (log scale)\n",
    "    \"max_depth\": tune.randint(4, 12), # Integer between 4 and 11 (exclusive upper bound for randint)\n",
    "    \"min_child_weight\": tune.choice([1, 2, 3, 4, 5]), # Choose from discrete values\n",
    "    \"subsample\": tune.uniform(0.6, 1.0), # Float between 0.6 and 1.0\n",
    "    \"colsample_bytree\": tune.uniform(0.6, 1.0), # Float between 0.6 and 1.0\n",
    "    # Explicitly include n_estimators here for the training function to access\n",
    "    \"n_estimators\": tune.randint(150, 501), # Integer between 150 and 500 (exclusive upper bound)\n",
    "    \"random_state\": 42 # Fixed seed for XGBoost internal randomness (passed in config)\n",
    "}\n",
    "\n",
    "# Configure the Tuner\n",
    "tuner = tune.Tuner(\n",
    "    train_fraud_model_ray, # The trainable function defined in the previous step\n",
    "    tune_config=tune.TuneConfig(\n",
    "        metric=\"recall\",       # Optimize based on the 'recall' key reported by tune.report\n",
    "        mode=\"max\",            # We want to maximize recall\n",
    "        num_samples=15,       # Number of different hyperparameter combinations to try\n",
    "        # Optional: Add scheduler for early stopping (uncomment to use)\n",
    "        # from ray.tune.schedulers import ASHAScheduler\n",
    "        # scheduler=ASHAScheduler(metric=\"recall\", mode=\"max\", grace_period=5, reduction_factor=2),\n",
    "    ),\n",
    "    param_space=param_space, # The search space defined above\n",
    "    # Optional: Add run_config for naming experiment, storage etc.\n",
    "    # run_config=ray.air.RunConfig(name=\"fraud_xgb_tune\")\n",
    ")\n",
    "\n",
    "print(\"Ray Tune Tuner configured successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154eab87-df7c-4cad-bd20-0cf16215d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to start Ray Tune experiment (tuner.fit())...\n",
      "Initializing Ray...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 04:38:52,052\tERROR services.py:1362 -- Failed to start the dashboard , return code 3221226505\n",
      "2025-05-03 04:38:52,053\tERROR services.py:1387 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2025-05-03 04:38:52,061\tERROR services.py:1431 -- \n",
      "The last 20 lines of C:\\Users\\amiru\\AppData\\Local\\Temp\\ray\\session_2025-05-03_04-38-50_215388_13868\\logs\\dashboard.log (it contains the error message from the dashboard): \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\AI Prep\\Projects\\Project 1\\realtime-fraud-detection-api\\p1env\\Lib\\site-packages\\ray\\dashboard\\dashboard.py\", line 247, in <module>\n",
      "    logging_utils.redirect_stdout_stderr_if_needed(\n",
      "  File \"E:\\AI Prep\\Projects\\Project 1\\realtime-fraud-detection-api\\p1env\\Lib\\site-packages\\ray\\_private\\logging_utils.py\", line 47, in redirect_stdout_stderr_if_needed\n",
      "    sys.stdout = open_log(stdout_fileno, unbuffered=True, closefd=False)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\AI Prep\\Projects\\Project 1\\realtime-fraud-detection-api\\p1env\\Lib\\site-packages\\ray\\_private\\utils.py\", line 446, in open_log\n",
      "    stream = open(path, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: [WinError 6] The handle is invalid\n",
      "\n",
      "\n",
      "2025-05-03 04:38:52,223\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "# --- REVISED Step 5: Run Ray Tune Experiment ---\n",
    "import ray\n",
    "import time\n",
    "\n",
    "print(\"\\nAttempting to start Ray Tune experiment (tuner.fit())...\")\n",
    "\n",
    "# --- Ensure Ray is shutdown before initializing ---\n",
    "if ray.is_initialized():\n",
    "    print(\"Shutting down existing Ray instance...\")\n",
    "    ray.shutdown()\n",
    "    time.sleep(1) # Short pause\n",
    "\n",
    "# --- Simplified Ray Initialization ---\n",
    "print(\"Initializing Ray...\")\n",
    "try:\n",
    "    ray.init(ignore_reinit_error=True)\n",
    "    print(\"Ray initialized.\")\n",
    "except Exception as init_e:\n",
    "    print(f\"!!! CRITICAL ERROR DURING ray.init(): {init_e}\")\n",
    "    # If init fails, no point proceeding\n",
    "    raise init_e # Stop execution here\n",
    "\n",
    "start_tune_time = time.time()\n",
    "best_result = None\n",
    "results = None # Initialize results\n",
    "\n",
    "try:\n",
    "    print(\"Attempting tuner.fit()...\")\n",
    "    # This starts the hyperparameter tuning process\n",
    "    results = tuner.fit() # <<< The actual tuning call >>>\n",
    "    end_tune_time = time.time()\n",
    "    print(f\"\\nRay Tune experiment tuner.fit() call finished. Total time: {end_tune_time - start_tune_time:.2f} seconds\") # Note: This finishing doesn't guarantee success\n",
    "\n",
    "    # --- Check Results AFTER tuner.fit() finishes ---\n",
    "    if results is None:\n",
    "         print(\"\\nERROR: Tuner fit call completed but returned None. Tuning likely failed silently.\")\n",
    "    else:\n",
    "        # Check if any trials resulted in errors\n",
    "        if results.errors:\n",
    "            print(\"\\nWARNING: Some trials encountered errors:\")\n",
    "            for i, trial_result in enumerate(results):\n",
    "                if trial_result.error:\n",
    "                    trial_id = trial_result.trial_id if hasattr(trial_result, 'trial_id') else f\"Trial_{i}\"\n",
    "                    print(f\"- {trial_id}: {trial_result.error}\")\n",
    "\n",
    "        # Get the best result\n",
    "        try:\n",
    "             best_result = results.get_best_result(metric=\"recall\", mode=\"max\")\n",
    "             if best_result:\n",
    "                 print(\"\\n--- Best Trial Information ---\")\n",
    "                 print(f\"Best trial config: {best_result.config}\")\n",
    "                 print(f\"Best trial final validation recall: {best_result.metrics.get('recall', 'N/A')}\")\n",
    "             else:\n",
    "                  print(\"\\nWARNING: No successful trials found or best result could not be determined.\")\n",
    "                  print(\"Check individual trial errors or tuning configuration.\")\n",
    "        except Exception as e_best:\n",
    "             print(f\"\\nERROR retrieving best result: {e_best}\")\n",
    "             print(\"Possibly no trials completed successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n!!! UNEXPECTED ERROR during tuner.fit() call: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc() # Print full traceback for unexpected errors during fit\n",
    "finally:\n",
    "    # Always try to shut down Ray\n",
    "    if ray.is_initialized():\n",
    "        print(\"\\nShutting down Ray instance...\")\n",
    "        ray.shutdown()\n",
    "        print(\"Ray runtime shut down.\")\n",
    "\n",
    "# --- End of REVISED Cell 5 ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09658486-1130-436d-8e28-daed5412e7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray was not initialized or already shut down.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "    print(\"Attempted Ray shutdown.\")\n",
    "else:\n",
    "    print(\"Ray was not initialized or already shut down.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e72fd9-9e74-4397-b17d-3f7c122d533a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[scikit-learn,tune] in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (2.45.0)\n",
      "Requirement already satisfied: click>=7.0 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (8.1.8)\n",
      "Requirement already satisfied: filelock in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (3.18.0)\n",
      "Requirement already satisfied: jsonschema in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (1.1.0)\n",
      "Requirement already satisfied: packaging in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (25.0)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (6.30.2)\n",
      "Requirement already satisfied: pyyaml in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (6.0.2)\n",
      "Requirement already satisfied: requests in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (2.32.3)\n",
      "Requirement already satisfied: pandas in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (2.2.3)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow>=9.0.0 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (20.0.0)\n",
      "Requirement already satisfied: fsspec in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from ray[scikit-learn,tune]) (2025.3.2)\n",
      "Requirement already satisfied: colorama in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from click>=7.0->ray[scikit-learn,tune]) (0.4.6)\n",
      "Requirement already satisfied: numpy in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from tensorboardX>=1.9->ray[scikit-learn,tune]) (2.2.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from jsonschema->ray[scikit-learn,tune]) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from jsonschema->ray[scikit-learn,tune]) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from jsonschema->ray[scikit-learn,tune]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from jsonschema->ray[scikit-learn,tune]) (0.24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from pandas->ray[scikit-learn,tune]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from pandas->ray[scikit-learn,tune]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from pandas->ray[scikit-learn,tune]) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from requests->ray[scikit-learn,tune]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from requests->ray[scikit-learn,tune]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from requests->ray[scikit-learn,tune]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from requests->ray[scikit-learn,tune]) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.5 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ray[scikit-learn,tune]) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from referencing>=0.28.4->jsonschema->ray[scikit-learn,tune]) (4.13.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ray 2.45.0 does not provide the extra 'scikit-learn'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install \"ray[tune,scikit-learn]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670b76c6-97ad-40ab-9e8a-91808fe33f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Using cached scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting hyperopt\n",
      "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from scikit-optimize) (1.4.2)\n",
      "Collecting pyaml>=16.9 (from scikit-optimize)\n",
      "  Using cached pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from scikit-optimize) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from scikit-optimize) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from scikit-optimize) (1.6.1)\n",
      "Requirement already satisfied: packaging>=21.3 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from scikit-optimize) (25.0)\n",
      "Requirement already satisfied: six in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from hyperopt) (1.17.0)\n",
      "Collecting networkx>=2.2 (from hyperopt)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting future (from hyperopt)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting tqdm (from hyperopt)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting cloudpickle (from hyperopt)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting py4j (from hyperopt)\n",
      "  Using cached py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: PyYAML in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
      "Requirement already satisfied: colorama in e:\\ai prep\\projects\\project 1\\realtime-fraud-detection-api\\p1renv\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n",
      "Using cached scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
      "Using cached hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
      "Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: py4j, tqdm, pyaml, networkx, future, cloudpickle, hyperopt, scikit-optimize\n",
      "Successfully installed cloudpickle-3.1.1 future-1.0.0 hyperopt-0.2.7 networkx-3.4.2 py4j-0.10.9.9 pyaml-25.1.0 scikit-optimize-0.10.2 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01ba888-169e-4c12-8044-f4f614aef640",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray.tune.sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tune\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mray\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtune\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TuneGridSearchCV  \u001b[38;5;66;03m# For Ray ≥2.10\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ray.tune.sklearn'"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune.sklearn import TuneGridSearchCV  # For Ray ≥2.10\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define parameter search space\n",
    "param_distributions = {\n",
    "    \"xgboost__n_estimators\": tune.randint(150, 500),\n",
    "    \"xgboost__max_depth\": tune.randint(4, 12),\n",
    "    \"xgboost__learning_rate\": tune.uniform(0.01, 0.2),\n",
    "    \"xgboost__subsample\": tune.uniform(0.6, 1.0),\n",
    "    \"xgboost__colsample_bytree\": tune.uniform(0.6, 1.0),\n",
    "}\n",
    "\n",
    "# Setup TuneGridSearchCV (Ray ≥2.10)\n",
    "tune_search = TuneGridSearchCV(\n",
    "    estimator=Pipeline([(\"xgboost\", XGBClassifier(tree_method=\"hist\"))]),\n",
    "    param_grid=param_distributions,\n",
    "    scoring=\"recall\",\n",
    "    cv=StratifiedKFold(3).split(X_train_fe_resampled, y_train_fe_resampled),\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    max_iters=15  # Number of trials\n",
    ")\n",
    "\n",
    "# Run tuning\n",
    "tune_search.fit(X_train_fe_resampled, y_train_fe_resampled)\n",
    "print(\"Best params:\", tune_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b234b2-454e-4360-b5da-7aea9902f28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tune-sklearn\n",
      "Version: 0.5.0\n",
      "Summary: A drop-in replacement for Scikit-Learn's GridSearchCV / RandomizedSearchCV with cutting edge hyperparameter tuning techniques.\n",
      "Home-page: https://github.com/ray-project/tune-sklearn\n",
      "Author: Michael Chau, Anthony Yu, and Ray Team\n",
      "Author-email: ray-dev@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: E:\\AI Prep\\Projects\\Project 1\\realtime-fraud-detection-api\\p1renv\\Lib\\site-packages\n",
      "Requires: numpy, ray, scikit-learn, scipy\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tune-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b69c782-27e1-45ca-baab-7e25be016594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.45.0\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "print(ray.__version__)  # Should be ≥2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172ce5f-de34-411a-8af7-53f9bbdb1533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detection-env",
   "language": "python",
   "name": "fraud-detection-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
