{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6bbe082-1614-4dac-997c-5cbb3ac3321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load full dataset from: hf://datasets/MatrixIA/FraudData/FraudData.csv\n",
      "Successfully loaded full dataset into Pandas DataFrame.\n",
      "Full DataFrame shape: (6362620, 11)\n",
      "Creating a sample of 1000000 rows for initial development...\n",
      "Sample DataFrame shape: (1000000, 11)\n",
      "\n",
      "First 5 rows (from sample):\n",
      "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
      "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
      "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
      "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
      "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
      "0  M1979787155             0.0             0.0        0               0  \n",
      "1  M2044282225             0.0             0.0        0               0  \n",
      "2   C553264065             0.0             0.0        1               0  \n",
      "3    C38997010         21182.0             0.0        1               0  \n",
      "4  M1230701703             0.0             0.0        0               0  \n",
      "\n",
      "DataFrame Info (from sample):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   step            1000000 non-null  int64  \n",
      " 1   type            1000000 non-null  object \n",
      " 2   amount          1000000 non-null  float64\n",
      " 3   nameOrig        1000000 non-null  object \n",
      " 4   oldbalanceOrg   1000000 non-null  float64\n",
      " 5   newbalanceOrig  1000000 non-null  float64\n",
      " 6   nameDest        1000000 non-null  object \n",
      " 7   oldbalanceDest  1000000 non-null  float64\n",
      " 8   newbalanceDest  1000000 non-null  float64\n",
      " 9   isFraud         1000000 non-null  int64  \n",
      " 10  isFlaggedFraud  1000000 non-null  int64  \n",
      "dtypes: float64(5), int64(3), object(3)\n",
      "memory usage: 83.9+ MB\n",
      "\n",
      "Summary Statistics (from sample):\n",
      "                 step        amount  oldbalanceOrg  newbalanceOrig  \\\n",
      "count  1000000.000000  1.000000e+06   1.000000e+06    1.000000e+06   \n",
      "mean        25.156387  1.602499e+05   8.776703e+05    8.983465e+05   \n",
      "std         12.652100  2.592584e+05   2.982420e+06    3.019326e+06   \n",
      "min          1.000000  1.000000e-01   0.000000e+00    0.000000e+00   \n",
      "25%         14.000000  1.275993e+04   0.000000e+00    0.000000e+00   \n",
      "50%         20.000000  7.953670e+04   1.595700e+04    0.000000e+00   \n",
      "75%         38.000000  2.166060e+05   1.397520e+05    1.797911e+05   \n",
      "max         45.000000  1.000000e+07   3.893942e+07    3.894623e+07   \n",
      "\n",
      "       oldbalanceDest  newbalanceDest         isFraud  isFlaggedFraud  \n",
      "count    1.000000e+06    1.000000e+06  1000000.000000       1000000.0  \n",
      "mean     9.860668e+05    1.125662e+06        0.000535             0.0  \n",
      "std      2.305423e+06    2.426587e+06        0.023124             0.0  \n",
      "min      0.000000e+00    0.000000e+00        0.000000             0.0  \n",
      "25%      0.000000e+00    0.000000e+00        0.000000             0.0  \n",
      "50%      1.349287e+05    2.301105e+05        0.000000             0.0  \n",
      "75%      9.268256e+05    1.167926e+06        0.000000             0.0  \n",
      "max      4.205466e+07    4.216916e+07        1.000000             0.0  \n",
      "\n",
      "Missing Values Count per Column (from sample):\n",
      "step              0\n",
      "type              0\n",
      "amount            0\n",
      "nameOrig          0\n",
      "oldbalanceOrg     0\n",
      "newbalanceOrig    0\n",
      "nameDest          0\n",
      "oldbalanceDest    0\n",
      "newbalanceDest    0\n",
      "isFraud           0\n",
      "isFlaggedFraud    0\n",
      "dtype: int64\n",
      "\n",
      "Class Distribution for Target Column ('isFraud') in Sample:\n",
      "isFraud\n",
      "0    0.999465\n",
      "1    0.000535\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Raw Counts in Sample:\n",
      "isFraud\n",
      "0    999465\n",
      "1       535\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the special Hugging Face URL for the CSV file\n",
    "# This tells pandas to use fsspec and huggingface_hub to find and read the file\n",
    "hf_csv_url = \"hf://datasets/MatrixIA/FraudData/FraudData.csv\"\n",
    "\n",
    "print(f\"Attempting to load full dataset from: {hf_csv_url}\")\n",
    "try:\n",
    "    # Use pandas read_csv directly with the hf:// URL\n",
    "    # This loads the entire dataset into memory. May take a minute or two.\n",
    "    df_full = pd.read_csv(hf_csv_url)\n",
    "    print(\"Successfully loaded full dataset into Pandas DataFrame.\")\n",
    "    print(f\"Full DataFrame shape: {df_full.shape}\")\n",
    "\n",
    "    # --- IMPORTANT: Create a Sample for Development ---\n",
    "    # Define sample size (e.g., 1 million rows)\n",
    "    sample_size = 1000000\n",
    "    print(f\"Creating a sample of {sample_size} rows for initial development...\")\n",
    "\n",
    "    # Option 1: Take the first N rows (simplest)\n",
    "    df = df_full.head(sample_size).copy()\n",
    "\n",
    "    # Option 2: Take a random sample (better representation, might be slightly slower)\n",
    "    # df = df_full.sample(n=sample_size, random_state=42).copy()\n",
    "\n",
    "    print(f\"Sample DataFrame shape: {df.shape}\")\n",
    "\n",
    "    # Optional: Delete the full dataframe to free memory if you notice slowdowns\n",
    "    # Although with 24GB RAM, it might not be necessary yet.\n",
    "    # del df_full\n",
    "    # import gc # Garbage collector\n",
    "    # gc.collect() # Force memory cleanup\n",
    "\n",
    "except Exception as e:\n",
    "    # Catch potential errors during download or reading\n",
    "    print(f\"ERROR: Failed to load dataset using pd.read_csv('hf://...'). Error: {e}\")\n",
    "    print(\"Check your internet connection, proxy settings (if any), and the URL.\")\n",
    "    raise # Stop execution\n",
    "\n",
    "# --- Basic Inspection (Run on the SAMPLE 'df') ---\n",
    "# This part remains the same as before, using the 'df' variable which now holds the sample\n",
    "print(\"\\nFirst 5 rows (from sample):\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataFrame Info (from sample):\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nSummary Statistics (from sample):\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing Values Count per Column (from sample):\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# --- Target Variable Check (Run on the SAMPLE 'df') ---\n",
    "# Target column is 'isFraud' for this dataset (PaySim)\n",
    "target_column = 'isFraud'\n",
    "\n",
    "if target_column in df.columns:\n",
    "    print(f\"\\nClass Distribution for Target Column ('{target_column}') in Sample:\")\n",
    "    print(df[target_column].value_counts(normalize=True))\n",
    "    print(\"\\nRaw Counts in Sample:\")\n",
    "    print(df[target_column].value_counts(normalize=False))\n",
    "else:\n",
    "    print(f\"\\nERROR: Target column '{target_column}' not found in the DataFrame!\")\n",
    "    print(f\"Available columns are: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f27c075-4799-4c72-927f-9f182e208fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating data profiling report on the SAMPLE... (This might take a minute or two)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e853de960b4c94b6f823cd2ab40bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                         | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|█████▉                                                           | 1/11 [00:03<00:29,  2.98s/it]\u001b[A\n",
      " 18%|███████████▊                                                     | 2/11 [00:03<00:15,  1.70s/it]\u001b[A\n",
      " 27%|█████████████████▋                                               | 3/11 [00:10<00:31,  3.97s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████| 11/11 [00:10<00:00,  1.03it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8fbdb7ca0d4f3eb5e5775880fdbe5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc52f9a8b2f42ffb082ffb436900cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc94846ba3849d8a841f71f0294e97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling report saved to fraud_data_profiling_report_sample.html\n"
     ]
    }
   ],
   "source": [
    "# Import the profiling tool\n",
    "try:\n",
    "    from ydata_profiling import ProfileReport\n",
    "except ImportError:\n",
    "    try:\n",
    "        from pandas_profiling import ProfileReport\n",
    "    except ImportError:\n",
    "        print(\"ERROR: Neither ydata-profiling nor pandas-profiling seem to be installed.\")\n",
    "        print(\"Please run: pip install ydata-profiling\")\n",
    "        raise # Stop if library isn't installed\n",
    "\n",
    "print(\"\\nGenerating data profiling report on the SAMPLE... (This might take a minute or two)\")\n",
    "\n",
    "# Create the report object using the SAMPLE DataFrame 'df'\n",
    "profile = ProfileReport(df, title=\"Fraud Data Profiling Report (Sample)\", explorative=True)\n",
    "\n",
    "# Define the filename for the HTML report\n",
    "report_filename = \"fraud_data_profiling_report_sample.html\"\n",
    "\n",
    "# Save the report to an HTML file\n",
    "profile.to_file(report_filename)\n",
    "\n",
    "print(f\"Profiling report saved to {report_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850fcbf0-0359-45d1-939e-94c97cf48915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Step 2: Basic Preprocessing ---\n",
      "Original sample shape: (1000000, 11)\n",
      "Keeping features: ['step', 'type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
      "Target variable: isFraud\n",
      "\n",
      "Created df_processed with selected columns.\n",
      "Shape after selecting features: (1000000, 8)\n",
      "First 5 rows of df_processed:\n",
      "   step      type    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0     1   PAYMENT   9839.64       170136.0       160296.36             0.0   \n",
      "1     1   PAYMENT   1864.28        21249.0        19384.72             0.0   \n",
      "2     1  TRANSFER    181.00          181.0            0.00             0.0   \n",
      "3     1  CASH_OUT    181.00          181.0            0.00         21182.0   \n",
      "4     1   PAYMENT  11668.14        41554.0        29885.86             0.0   \n",
      "\n",
      "   newbalanceDest  isFraud  \n",
      "0             0.0        0  \n",
      "1             0.0        0  \n",
      "2             0.0        1  \n",
      "3             0.0        1  \n",
      "4             0.0        0  \n"
     ]
    }
   ],
   "source": [
    "#Step 2 Level 1: Preprocessing-and-Baseline\n",
    "# --- Step 2: Basic Preprocessing ---\n",
    "print(\"--- Starting Step 2: Basic Preprocessing ---\")\n",
    "\n",
    "# --- Step 2.1: Feature Selection ---\n",
    "# First, ensure 'df' holds the sample DataFrame from Step 1\n",
    "# (If in a new notebook, you might need to re-load/re-sample or load from a saved file)\n",
    "print(f\"Original sample shape: {df.shape}\")\n",
    "\n",
    "# Define the features we decided to keep\n",
    "features_to_keep = ['step', 'type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "target = 'isFraud' # Define the target column name\n",
    "\n",
    "print(f\"Keeping features: {features_to_keep}\")\n",
    "print(f\"Target variable: {target}\")\n",
    "\n",
    "try:\n",
    "    # Create a new DataFrame containing only the selected features and the target\n",
    "    # Using .copy() prevents accidental changes to the original 'df'\n",
    "    df_processed = df[features_to_keep + [target]].copy()\n",
    "\n",
    "    print(\"\\nCreated df_processed with selected columns.\")\n",
    "    print(f\"Shape after selecting features: {df_processed.shape}\")\n",
    "    print(\"First 5 rows of df_processed:\")\n",
    "    print(df_processed.head())\n",
    "except KeyError as e:\n",
    "    print(f\"ERROR: A specified column was not found in the DataFrame: {e}\")\n",
    "    print(\"Please check the 'features_to_keep' list and the 'target' variable against the columns from df.info().\")\n",
    "    raise # Stop execution if columns are incorrect\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during feature selection: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "641233c4-ff29-4aa5-a442-8455fdbfc3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types before encoding:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   step            1000000 non-null  int64  \n",
      " 1   type            1000000 non-null  object \n",
      " 2   amount          1000000 non-null  float64\n",
      " 3   oldbalanceOrg   1000000 non-null  float64\n",
      " 4   newbalanceOrig  1000000 non-null  float64\n",
      " 5   oldbalanceDest  1000000 non-null  float64\n",
      " 6   newbalanceDest  1000000 non-null  float64\n",
      " 7   isFraud         1000000 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 61.0+ MB\n",
      "None\n",
      "\n",
      "Unique values in 'type' column:\n",
      "['PAYMENT' 'TRANSFER' 'CASH_OUT' 'DEBIT' 'CASH_IN']\n",
      "\n",
      "Value counts for 'type':\n",
      "type\n",
      "CASH_OUT    362676\n",
      "PAYMENT     329753\n",
      "CASH_IN     218673\n",
      "TRANSFER     82424\n",
      "DEBIT         6474\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Applying one-hot encoding to: ['type'] using pd.get_dummies...\n",
      "\n",
      "DataFrame after one-hot encoding:\n",
      "   step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0     1   9839.64       170136.0       160296.36             0.0   \n",
      "1     1   1864.28        21249.0        19384.72             0.0   \n",
      "2     1    181.00          181.0            0.00             0.0   \n",
      "3     1    181.00          181.0            0.00         21182.0   \n",
      "4     1  11668.14        41554.0        29885.86             0.0   \n",
      "\n",
      "   newbalanceDest  isFraud  type_CASH_OUT  type_DEBIT  type_PAYMENT  \\\n",
      "0             0.0        0          False       False          True   \n",
      "1             0.0        0          False       False          True   \n",
      "2             0.0        1          False       False         False   \n",
      "3             0.0        1           True       False         False   \n",
      "4             0.0        0          False       False          True   \n",
      "\n",
      "   type_TRANSFER  \n",
      "0          False  \n",
      "1          False  \n",
      "2           True  \n",
      "3          False  \n",
      "4          False  \n",
      "\n",
      "Shape after encoding: (1000000, 11)\n",
      "\n",
      "Data types after encoding:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   step            1000000 non-null  int64  \n",
      " 1   amount          1000000 non-null  float64\n",
      " 2   oldbalanceOrg   1000000 non-null  float64\n",
      " 3   newbalanceOrig  1000000 non-null  float64\n",
      " 4   oldbalanceDest  1000000 non-null  float64\n",
      " 5   newbalanceDest  1000000 non-null  float64\n",
      " 6   isFraud         1000000 non-null  int64  \n",
      " 7   type_CASH_OUT   1000000 non-null  bool   \n",
      " 8   type_DEBIT      1000000 non-null  bool   \n",
      " 9   type_PAYMENT    1000000 non-null  bool   \n",
      " 10  type_TRANSFER   1000000 non-null  bool   \n",
      "dtypes: bool(4), float64(5), int64(2)\n",
      "memory usage: 57.2 MB\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2.2: Encode Categorical Features ('type') ---\n",
    "\n",
    "# Identify the categorical column(s) remaining in df_processed\n",
    "categorical_cols = ['type']\n",
    "\n",
    "# Check current data types and unique values in 'type' before encoding\n",
    "print(\"\\nData types before encoding:\")\n",
    "print(df_processed.info()) # Check df_processed specifically\n",
    "if 'type' in df_processed.columns:\n",
    "    print(f\"\\nUnique values in 'type' column:\\n{df_processed['type'].unique()}\")\n",
    "    print(f\"\\nValue counts for 'type':\\n{df_processed['type'].value_counts()}\")\n",
    "else:\n",
    "    print(\"\\n'type' column not found in df_processed (already dropped or renamed?).\")\n",
    "\n",
    "\n",
    "print(f\"\\nApplying one-hot encoding to: {categorical_cols} using pd.get_dummies...\")\n",
    "\n",
    "try:\n",
    "    # Use pd.get_dummies to convert the 'type' column\n",
    "    # drop_first=True removes redundancy (prevents multicollinearity)\n",
    "    df_processed = pd.get_dummies(df_processed, columns=categorical_cols, drop_first=True) # This line reassigns df_processed\n",
    "\n",
    "    print(\"\\nDataFrame after one-hot encoding:\")\n",
    "    print(df_processed.head()) # Notice the original 'type' column is gone\n",
    "                               # and new 'type_TRANSFER', 'type_PAYMENT', etc. columns appear\n",
    "    print(f\"\\nShape after encoding: {df_processed.shape}\")\n",
    "\n",
    "    # Verify that all columns (except potentially target) are now numerical\n",
    "    print(\"\\nData types after encoding:\")\n",
    "    df_processed.info()\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"ERROR: Column specified for encoding not found: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during one-hot encoding: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f7f52a-842b-472e-8cab-05b1199a4178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Separating features (X) and target ('isFraud')...\n",
      "Separation complete.\n",
      "\n",
      "Features (X) verification:\n",
      "  Shape: (1000000, 10)\n",
      "  Target column 'isFraud' successfully removed from X.\n",
      "  First 5 rows of X:\n",
      "   step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
      "0     1   9839.64       170136.0       160296.36             0.0   \n",
      "1     1   1864.28        21249.0        19384.72             0.0   \n",
      "2     1    181.00          181.0            0.00             0.0   \n",
      "3     1    181.00          181.0            0.00         21182.0   \n",
      "4     1  11668.14        41554.0        29885.86             0.0   \n",
      "\n",
      "   newbalanceDest  type_CASH_OUT  type_DEBIT  type_PAYMENT  type_TRANSFER  \n",
      "0             0.0          False       False          True          False  \n",
      "1             0.0          False       False          True          False  \n",
      "2             0.0          False       False         False           True  \n",
      "3             0.0           True       False         False          False  \n",
      "4             0.0          False       False          True          False  \n",
      "\n",
      "Target (y) verification:\n",
      "  Shape: (1000000,)\n",
      "  Data type: int64\n",
      "  First 5 values of y:\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: isFraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2.3: Separate Features (X) and Target (y) ---\n",
    "\n",
    "# Ensure the target variable name is correctly defined\n",
    "target = 'isFraud'\n",
    "\n",
    "print(f\"\\nSeparating features (X) and target ('{target}')...\")\n",
    "\n",
    "try:\n",
    "    # IMPORTANT: Make sure 'df_processed' is the DataFrame from the previous step\n",
    "    # containing the one-hot encoded 'type' columns.\n",
    "\n",
    "    # Create the features DataFrame 'X' by dropping the target column\n",
    "    # axis=1 specifies we are dropping a column\n",
    "    X = df_processed.drop(target, axis=1) # X should have 10 columns\n",
    "\n",
    "    # Create the target Series 'y' by selecting only the target column\n",
    "    y = df_processed[target] # y should be a Series\n",
    "\n",
    "    # --- Verification ---\n",
    "    print(\"Separation complete.\")\n",
    "    print(\"\\nFeatures (X) verification:\")\n",
    "    print(f\"  Shape: {X.shape}\") # Expect (1000000, 10)\n",
    "    if target in X.columns:\n",
    "         print(f\"  ERROR: Target column '{target}' still present in X!\")\n",
    "    else:\n",
    "         print(f\"  Target column '{target}' successfully removed from X.\")\n",
    "    print(\"  First 5 rows of X:\")\n",
    "    print(X.head())\n",
    "    print(\"\\nTarget (y) verification:\")\n",
    "    print(f\"  Shape: {y.shape}\") # Expect (1000000,)\n",
    "    print(f\"  Data type: {y.dtype}\") # Expect int64\n",
    "    print(\"  First 5 values of y:\")\n",
    "    print(y.head())\n",
    "\n",
    "except KeyError:\n",
    "    print(f\"ERROR: Could not find target column '{target}' in df_processed.\")\n",
    "    print(f\"Available columns are: {list(df_processed.columns)}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during X/y separation: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b09d9f-4a14-4dcf-a599-4bf711d59c10",
   "metadata": {},
   "source": [
    "Excellent! That output is perfect and confirms you have successfully completed Step 2.3: Separate Features (X) and Target (y).\n",
    "\n",
    "X now has the correct shape (1M rows, 10 feature columns).\n",
    "\n",
    "y now has the correct shape (1M rows, 1 target column as a Series) and data type (int64).\n",
    "\n",
    "The verification checks confirm the target was correctly removed from X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecc5ca-07ae-4f5d-be92-94edf00c3ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-detection-env",
   "language": "python",
   "name": "fraud-detection-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
